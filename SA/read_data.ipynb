{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '238.json', 'sentence_scores': [['An anonymous e-mail says Barack Obama took the oath of office for the U.S. Senate on a Koran, the holy book of Islam.', 0.6007211804389954], ['We thought it would be odd if that were true, since Obama is a Christian.', 0.5864729285240173], ['In fact, it is wrong.', 0.6335600018501282], ['The e-mail also spells the book\\'s name \"Kuran,\" though usually it is spelled Koran or Quran.', 0.7251154780387878], [\"Two press reports from Obama's swearing-in ceremony in January 2005 mention specifically that Obama took the oath of office by placing his hand on his own copy of the Bible.\", 0.7941301465034485], ['The Barack Obama campaign also confirmed that it was a Bible and that the book belonged to Obama.', 0.781171441078186], ['Vice President Dick Cheney, in his role as president of the Senate, administered the oath.', 0.6896082758903503], ['After being raised outside of any particular faith tradition, Obama became a Christian in his mid 20s and is a member of Trinity United Church of Christ in Chicago.', 0.3266814649105072], ['(Obama gave what are arguably his most extended remarks on his faith at the \"Call to Renewal\" religious conference in 2006; read the speech here .)', 0.3161579370498657]]}\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../../results_serialized_val_filtered.jsonl\" #Each line is a json\n",
    "\n",
    "ids_sentscores = []\n",
    "with open(file_path) as f:\n",
    "    for test_sample in f:\n",
    "        ids_sentscores.append(json.loads(test_sample))\n",
    "print(ids_sentscores[1])\n",
    "# original_justifications = []\n",
    "# for samp in ids_sentscores:\n",
    "#     temp_ls = []\n",
    "#     temp_dict = {}\n",
    "#     top_justifications = sorted(samp['sentence_scores'], reverse=True, key = lambda x: x[1])[:6]\n",
    "    \n",
    "#     for sent in top_justifications:\n",
    "#         temp_ls.append(sent[0].strip() + \"<>\")\n",
    "    \n",
    "#     temp_dict[\"id\"] = samp[\"id\"]\n",
    "#     temp_dict[\"justifications\"] = \" \".join(temp_ls)\n",
    "#     original_justifications.append(temp_dict)\n",
    "#     print(temp_dict)\n",
    "    \n",
    "# json.dump(original_justifications, open('../../top6_val_justifications_sep.json','w+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../results_serialized_val_filtered.jsonl\" #Each line is a json\n",
    "\n",
    "ids_sentscores = []\n",
    "with open(file_path) as f:\n",
    "    for test_sample in f:\n",
    "        ids_sentscores.append(json.loads(test_sample))\n",
    "        \n",
    "top_justifications = sorted(ids_sentscores[0]['sentence_scores'], reverse=True, key = lambda x: x[1])[:6]\n",
    "print(top_justifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Building a wall on the border? will take literally years. Rick Perry, agog. Perryâ€™s assertion got us thinking\"\n",
    "new_a1 = a.split(\".\")\n",
    "new_a2 = str(a.split(\".\")).split(\"?\")\n",
    "\n",
    "\n",
    "print(new_a1)\n",
    "for i in new_a1:\n",
    "    print(i)\n",
    "    print(\"--------\")\n",
    "\n",
    "print(new_a2)\n",
    "for i in new_a2:\n",
    "    print(i)\n",
    "    print(\"--------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Debugging of GPT2\n",
    "\n",
    "# print([tokenizer.decode(idx) for idx in tensor_input.cpu()[0].tolist()])\n",
    "# print(tensor_input.shape)\n",
    "# print(logits.shape) #(1, 11, 50257)\n",
    "# preds = -torch.gather(input=F.softmax(logits[:, :-1,:], dim=2), index=tensor_input[:,1:].unsqueeze(2), dim=2).squeeze().log()\n",
    "# print(preds)\n",
    "# print(preds.mean().exp())\n",
    "# print(\"ppl\", math.exp(loss.item()))\n",
    "# input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
