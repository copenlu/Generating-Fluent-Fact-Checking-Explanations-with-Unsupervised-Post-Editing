{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../results_pepa/results_serialized_test.jsonl\" #Each line is a json\n",
    "\n",
    "ids_sentscores = []\n",
    "with open(file_path) as f:\n",
    "    for test_sample in f:\n",
    "        ids_sentscores.append(json.loads(test_sample))\n",
    "\n",
    "original_justifications = []\n",
    "for samp in ids_sentscores:\n",
    "    temp_ls = []\n",
    "    temp_dict = {}\n",
    "    top_justifications = sorted(samp['sentence_scores'], reverse=True, key = lambda x: x[1])[:6]\n",
    "    for sent in top_justifications:\n",
    "        temp_ls.append(sent[0].strip())\n",
    "    \n",
    "    temp_dict[\"id\"] = samp[\"id\"]\n",
    "    temp_dict[\"justifications\"] = \" \".join(temp_ls)\n",
    "    \n",
    "    original_justifications.append(temp_dict)\n",
    "    \n",
    "#json.dump(original_justifications, open('../../top6_test_justifications.json','w+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"../org_justs_val.json\", \"r\"))\n",
    "batch_data = data[0:3]\n",
    "\n",
    "input_batch = list(zip(*[[i[\"id\"], i[\"justs\"]] for i in batch_data]))\n",
    "ids = list(input_batch[0])\n",
    "ref_orgs = list(input_batch[1])\n",
    "\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = [random.randint(0,len(i.strip().split(\" \"))-1) for i in ref_orgs]\n",
    "print(positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ref_orgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_hats = self.editor.edit(ref_olds, ops, positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Debugging of GPT2\n",
    "\n",
    "# print([tokenizer.decode(idx) for idx in tensor_input.cpu()[0].tolist()])\n",
    "# print(tensor_input.shape)\n",
    "# print(logits.shape) #(1, 11, 50257)\n",
    "# preds = -torch.gather(input=F.softmax(logits[:, :-1,:], dim=2), index=tensor_input[:,1:].unsqueeze(2), dim=2).squeeze().log()\n",
    "# print(preds)\n",
    "# print(preds.mean().exp())\n",
    "# print(\"ppl\", math.exp(loss.item()))\n",
    "# input()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
