{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "\n",
    "parser = CoreNLPParser('http://localhost:9000', encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(\"cpu\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ġbought', 'Ġbananas', ',', 'Ġapples', ',', 'Ġand', 'Ġorange', 'Ġjuice', 'Ġfrom', 'Ġthe', 'Ġsupermarket', '.']\n",
      "tensor([[ 9.1669, 11.3402,  2.1985,  4.7560,  0.5062,  1.7837,  5.7995,  0.4455,\n",
      "          1.8520,  1.7130,  2.1359,  1.2360]], grad_fn=<ViewBackward>)\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([42.9334], grad_fn=<SumBackward1>)\n",
      "tensor([12])\n",
      "tensor([3.5778], grad_fn=<DivBackward0>)\n",
      "\n",
      "Final: tensor([2.7937], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def scorer_batch(sentences):\n",
    "    #Gpt for fluency\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tensor_input = {k: v.to(\"cpu\") for k,v in tokenizer(sentences, padding=True, truncation=True, return_tensors='pt').items()}\n",
    "\n",
    "\n",
    "    lm_labels = tensor_input[\"input_ids\"].detach().clone()\n",
    "    lm_labels[lm_labels[:, :] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "    outputs = model(input_ids=tensor_input[\"input_ids\"],\n",
    "                attention_mask= tensor_input[\"attention_mask\"],\n",
    "                return_dict=True)\n",
    "\n",
    "    lm_logits = outputs.logits\n",
    "    shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "    shift_labels = lm_labels[..., 1:].contiguous()\n",
    "    \n",
    "    print([tokenizer._convert_id_to_token(i) for i in shift_labels.tolist()[0]])\n",
    "\n",
    "    loss_fct = CrossEntropyLoss(ignore_index=-100, reduction='none')  # give CE loss at each word generation step\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    \n",
    "    log_prob_sum = loss.reshape(-1, shift_labels.shape[-1]) #.sum(dim=1)\n",
    "    log_prob_sum1 = torch.exp(-loss.reshape(-1, shift_labels.shape[-1])) #.sum(dim=1)\n",
    "    len_sum = tensor_input[\"attention_mask\"][..., 1:].contiguous() #.sum(dim=1)\n",
    "    \n",
    "    #prob_products_per_sample = torch.exp(-1 * (log_prob_sum/len_sum)).cpu()\n",
    "\n",
    "    print(log_prob_sum)\n",
    "    #print(log_prob_sum1)\n",
    "    print(len_sum)\n",
    "    \n",
    "    print(log_prob_sum.sum(dim=1))\n",
    "    #print(log_prob_sum1)\n",
    "    print(len_sum.sum(dim=1))\n",
    "    print(log_prob_sum.sum(dim=1) / len_sum.sum(dim=1))\n",
    "    \n",
    "    print(\"\\nFinal:\", 100 * torch.exp(- 1 * (log_prob_sum.sum(dim=1) / len_sum.sum(dim=1))))\n",
    "    \n",
    "    #return (prob_products_per_sample * 100)\n",
    "    \n",
    "sents = ['I bought bananas, apples, and orange juice from the supermarket.']\n",
    "scorer_batch(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ġbought', 'Ġbananas', ',', 'Ġapples', ',', 'Ġand', 'Ġorange', 'Ġjuice', 'Ġfrom', 'Ġthe', 'Ġsupermarket', '.']\n",
      "tensor([[ 9.1669, 11.3402,  2.1985,  4.7560,  0.5062,  1.7837,  5.7995,  0.4455,\n",
      "          1.8520,  1.7130,  2.1359,  1.2360]], grad_fn=<ViewBackward>)\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([42.9334], grad_fn=<SumBackward1>)\n",
      "tensor([12])\n",
      "tensor([3.5778], grad_fn=<DivBackward0>)\n",
      "\n",
      "Final: tensor([2.7937], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sents = ['I bought bananas, apples, and orange juice from the supermarket.']\n",
    "scorer_batch(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ġbought', 'Ġbananas', 'Ġfrom', 'Ġthe', 'Ġsupermarket', '.']\n",
      "\n",
      "Final: tensor([0.9943], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sents = ['I bought bananas from the supermarket.']\n",
    "scorer_batch(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(sent):\n",
    "    sent = sent.replace(\"’\", \"'\")\n",
    "    sent = sent.replace(\"‘\", \"`\")\n",
    "    sent = sent.replace('\"', \"''\")\n",
    "    sent = sent.replace(\"—\", \"--\")\n",
    "    sent = sent.replace(\"…\", \"...\")\n",
    "    sent = sent.replace(\"–\", \"--\")\n",
    "\n",
    "    return sent\n",
    "\n",
    "def get_dataset(scored_sentences_path, dataset_path, dataset_name, top_n, parser):\n",
    "\n",
    "    if dataset_name == 'liar_plus':\n",
    "        df = pd.read_csv(dataset_path, sep='\\t', index_col=0)\n",
    "        df = df.dropna()\n",
    "        columns = ['dummy', 'id', 'statement', 'justification',\n",
    "               'ruling_without_summary', 'label', 'just_tokenized',\n",
    "               'ruling_tokenized', 'statement_tokenized', 'oracle_ids']\n",
    "        print(df.columns)\n",
    "        print(columns)\n",
    "        df.columns = columns\n",
    "        \n",
    "    elif dataset_name == 'pub_health':\n",
    "        df = pd.read_csv(dataset_path, sep='\\t', index_col=0)\n",
    "        df = df.dropna()\n",
    "        \n",
    "        columns = ['claim_id', 'claim', 'date_published', 'explanation',\n",
    "                   'fact_checkers', 'main_text', 'sources', 'label', 'subjects']\n",
    "        \n",
    "        if len(df.columns) == 10:\n",
    "            columns = ['dummy'] + columns\n",
    "        \n",
    "        df.columns = columns\n",
    "        \n",
    "    scored_sentences = [json.loads(line) for line in open(scored_sentences_path)]\n",
    "    scored_sentences = {item[\"id\"]: sorted(item['sentence_scores'], key=lambda x: x[1], reverse=True)[:top_n] for item in scored_sentences}\n",
    "    \n",
    "    \n",
    "    inp_scored_sentences = {}\n",
    "    for k, v in scored_sentences.items():\n",
    "        \n",
    "        temp = []\n",
    "        for sent in v:\n",
    "            temp.append(sent[0])\n",
    "        inp_scored_sentences[k] = clean_str(\" \".join(temp))\n",
    "\n",
    "    scored_sentences = inp_scored_sentences\n",
    "    \n",
    "    \n",
    "    if dataset_name == 'liar_plus':\n",
    "        \n",
    "        df['scored_sentences'] = df.apply(lambda x: scored_sentences.get(x['id'], None), axis=1)\n",
    "        df = df[df['scored_sentences'] != None]\n",
    "        df['justification_sentences'] = df.apply(lambda x: sent_tokenize(x['justification']), axis=1)\n",
    "        df = df[['id', 'statement', 'justification', 'label', 'scored_sentences',\n",
    "             'justification_sentences']]\n",
    "        \n",
    "    elif dataset_name == 'pub_health':\n",
    "        df['claim_id'] = df['claim_id'].astype('str')\n",
    "        df['scored_sentences'] = df.apply(lambda x: scored_sentences.get(x['claim_id'], None), axis=1)\n",
    "        df = df[df['scored_sentences'] != None]\n",
    "        df['justification_sentences'] = df.apply(lambda x: sent_tokenize(x['explanation']), axis=1)\n",
    "        df = df[['claim_id', 'claim', 'explanation', 'label', 'scored_sentences',\n",
    "             'justification_sentences']]\n",
    "        \n",
    "        \n",
    "    dataset = [row.to_dict() for i, row in df.iterrows()]\n",
    "    new_dataset = []\n",
    "    if dataset_name == 'liar_plus':\n",
    "        for i in dataset:\n",
    "            if i[\"scored_sentences\"] is None or i[\"id\"] == '2001.json': #Sentence in Liarplus is too long:\n",
    "                continue\n",
    "            else:\n",
    "                new_dataset.append(i)\n",
    "    elif dataset_name == 'pub_health':\n",
    "        for i in dataset:\n",
    "        \n",
    "            if i[\"scored_sentences\"] is None or i[\"scored_sentences\"] == None:\n",
    "                continue\n",
    "            else:\n",
    "                new_dataset.append(i)\n",
    "    \n",
    "\n",
    "    print(f'Size of dataset: {len(dataset)}')\n",
    "    print(f'Size of new dataset: {len(new_dataset)}')\n",
    "    print('Sample: ', dataset[0])\n",
    "    if len(new_dataset)!=0:\n",
    "        print('Sample: ', new_dataset[0])\n",
    "\n",
    "    return \n",
    "\n",
    "scored_sentences_path = \"../../DATA-COPE-Project-DIKUServer/unsup_scores_liar/sentence_scores_val.jsonl\" #Each line is a json\n",
    "scored_sentences_path1 = \"../../DATA-COPE-Project-DIKUServer/unsup_scores_pubhealth/sentence_scores_test.jsonl\"\n",
    "\n",
    "dataset_path = \"../../liar_data/ruling_oracles_val.tsv\"\n",
    "dataset_path1 = \"../../DATA-COPE-Project-DIKUServer/PUBHEALTH/test.tsv\"\n",
    "\n",
    "get_dataset(scored_sentences_path1, dataset_path1, 'pub_health', 6, parser)\n",
    "#get_dataset(scored_sentences_path, dataset_path, 'liar_plus', 6, parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
