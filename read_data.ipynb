{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "\n",
    "from data_loader import get_dataset_df\n",
    "from run_sa import get_dataset\n",
    "from rouge_score import rouge_scorer\n",
    "from SA.args import get_model_args\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from nltk.parse.corenlp import CoreNLPParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CoreNLPParser('http://localhost:9000', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(C=300, algo_type='noSA', batch_size=1, dataset_name='pubhealth', dataset_path='/Users/jolly/PycharmProjects/COPENLU/liar_data/ruling_oracles_val.tsv', delete_th=0.97, device_type='cpu', editor_model_id='roberta-base', fluency_weight=1.4, fluencyscorer_model_id='gpt2', insert_th=1.1, length_weight=1.25, max_steps=200, min_length_of_edited_sent=40, named_entity_score_weight=0.95, outdir='', outfile='', outfile_filtered='', outfile_pegasus='', pegasus_modelname='tuner007/pegasus_paraphrase', reorder_th=0.95, sample=None, sbertname_pegasus='paraphrase-distilroberta-base-v1', seed=33, semantic_weight_keywords=1.0, semantic_weight_sentences=1.1, sentences_path='/Users/jolly/PycharmProjects/COPENLU/results_serialized_val_filtered.jsonl', split='test', t_init=60000, top_n=6)\n",
      "Size of dataset: 1232\n",
      "Sample:  {'claim_id': '33456', 'statement': 'A mother revealed to her child in a letter after her death that she had just one eye because she had donated the other to him.', 'justification': 'The one-eyed mother story expounds upon two moral messages: the unconditional, all-encompassing love we expect mothers to always feel for their children, and the admonition to not put off cherishing loved ones and appreciating their sacrifices while they’re still around.', 'ruling_without_summary': \"In April 2005, we spotted a tearjerker on the Internet about a mother who gave up one of her eyes to a son who had lost one of his at an early age. By February 2007 the item was circulating in e-mail in the following shortened version:  My mom only had one eye. I hated her… She was such an embarrassment. She cooked for students and teachers to support the family. There was this one day during elementary school where my mom came to say hello to me. I was so embarrassed. How could she do this to me? I ignored her, threw her a hateful look and ran out. The next day at school one of my classmates said, “EEEE, your mom only has one eye!” I wanted to bury myself. I also wanted my mom to just disappear. I confronted her that day and said, “If you’re only gonna make me a laughing stock, why don’t you just die?” My mom did not respond… I didn’t even stop to think for a second about what I had said, because I was full of anger. I was oblivious to her feelings. I wanted out of that house, and have nothing to do with her. So I studied real hard, got a chance to go abroad to study. Then, I got married. I bought a house of my own. I had kids of my own. I was happy with my life, my kids and the comforts. Then one day, my Mother came to visit me. She hadn’t seen me in years and she didn’t even meet her grandchildren. When she stood by the door, my children laughed at her, and I yelled at her for coming over uninvited. I screamed at her, “How dare you come to my house and scare my children! GET OUT OF HERE! NOW!! !” And to this, my mother quietly answered, “Oh, I’m so sorry. I may have gotten the wrong address,” and she disappeared out of sight. One day, a letter regarding a school reunion came to my house. So I lied to my wife that I was going on a business trip. After the reunion, I went to the old shack just out of curiosity. My neighbors said that she died. I did not shed a single tear. They handed me a letter that she had wanted me to have. My dearest son, I think of you all the time. I’m sorry that I came to your house and scared your children. I was so glad when I heard you were coming for the reunion. But I may not be able to even get out of bed to see you. I’m sorry that I was a constant embarrassment to you when you were growing up. You see……..when you were very little, you got into an accident, and lost your eye. As a mother, I couldn’t stand watching you having to grow up with one eye. So I gave you mine. I was so proud of my son who was seeing a whole new world for me, in my place, with that eye. With all my love to you, Your mother. In its earlier incarnation, the story identified by implication its location as Korea through statements made by both the mother and the son (the son’s “I left my mother and came to Seoul” and the mother’s “I won’t visit Seoul anymore”). It also supplied a reason for the son’s behavior when his mother arrived unexpectedly to visit him (“My little girl ran away, scared of my mom’s eye” and “I screamed at her, ‘How dare you come to my house and scare my daughter!'”). A further twist was provided in the original: rather than gaining the news of his mother’s death from neighbors (who hand him her letter), the son instead discovered the woman who bore him lying dead on the floor of what used to be his childhood home, her missive to him clutched in her lifeless hand: Give your parents roses while they are alive, not deadMY mom only had one eye. I hated her … she was such an embarrassment. My mom ran a small shop at a flea market. She collected little weeds and such to sell … anything for the money we needed she was such an embarrassment. There was this one day during elementary school … It was field day, and my mom came. I was so embarrassed. How could she do this to me? I threw her a hateful look and ran out. The next day at school … “your mom only has one eye?!? !” … And they taunted me. I wished that my mom would just disappear from this world so I said to my mom, “mom … Why don’t you have the other eye?! If you’re only going to make me a laughingstock, why don’t you just die?!! !” my mom did not respond … I guess I felt a little bad, but at the same time, it felt good to think that I had said what I’d wanted to say all this time… maybe it was because my mom hadn’t punished me, but I didn’t think that I had hurt her feelings very badly. That night… I woke up, and went to the kitchen to get a glass of water. My mom was crying there, so quietly, as if she was afraid that she might wake me. I took a look at her, and then turned away. Because of the thing I had said to her earlier, there was something pinching at me in the corner of my heart. Even so, I hated my mother who was crying out of her one eye. So I told myself that I would grow up and become successful. Because I hated my one-eyed mom and our desperate poverty… then I studied real hard. I left my mother and came to Seoul and studied, and got accepted in the Seoul University with all the confidence I had. Then, I got married. I bought a house of my own. Then I had kids, too… now I’m living happily as a successful man. I like it here because it’s a place that doesn’t remind me of my mom. This happiness was getting bigger and bigger, when… what?! Who’s this…it was my mother… still with her one eye. It felt as if the whole sky was falling apart on me. My little girl ran away, scared of my mom’s eye. And I asked her, “who are you? !” “I don’t know you!! !” as if trying to make that real. I screamed at her, “How dare you come to my house and scare my daughter!” “GET OUT OF HERE! NOW!! !” and to this, my mother quietly answered, “oh, I’m so sorry. I may have gotten the wrong address,” and she disappeared out of sight. Thank goodness… she doesn’t recognize me… I was quite relieved. I told myself that I wasn’t going to care, or think about this for the rest of my life. Then a wave of relief came upon me… One day, a letter regarding a school reunion came to my house. So, lying to my wife that I was going on a business trip, I went. After the reunion, I went down to the old shack, that I used to call a house… just out of curiosity there, I found my mother fallen on the cold ground. But I did not shed a single tear. She had a piece of paper in her hand…. it was a letter to me. My son… I think my life has been long enough now… And… I won’t visit Seoul anymore… but would it be too much to ask if I wanted you to come visit me once in a while? I miss you so much… and I was so glad when I heard you were coming for the reunion. But I decided not to go to the school. …for you… and I’m sorry that I only have one eye, and I was an embarrassment for you. You see, when you were very little, you got into an accident, and lost your eye. as a mom, I couldn’t stand watching you having to grow up with only one eye… so I gave you mine… I was so proud of my son that was seeing a whole new world for me, in my place, with that eye. I was never upset at you for anything you did… the couple times that you were angry with me, I thought to myself, ‘it’s because he loves me…’ my son. Oh, my son… I don’t want you to cry for me, because of my death. My son, I love you my son, I love you so much. With all modern medical technology, transplantation of the eyeball is still impossible. The optic nerve isn’t an ordinary nerve, but instead an inset running from the brain. Modern medicine isn’t able to “connect” an eyeball back to brain after an optic nerve has been severed, let alone transplant the eye from a different person. (The only exception is the cornea, the transparent part in front of the eye: corneas are transplanted to replace injured and opaque ones.) We won’t try to comment on whether any surgeon would accept an eye from a living donor for transplant into another — we’ll leave that to others who are far more knowledgeable about medical ethics and transplant procedures. But we will note that the plot device of a mother’s dramatic sacrifice for the sake of her child’s being revealed in a written communication delivered after her demise appears in another legend about maternal love: the 2008 tale about a woman who left a touching message on her cell phone even as life ebbed from her as she used her body to shield the tot during an earthquake. Giving up one’s own life for a loved one is central to a 2005 urban legend about a boy on a motorcycle who has his girlfriend hug him one last time and put on his helmet just before the crash that kills him and spares her. Returning to the “notes from the dead” theme is the 1995 story about a son who discovers only through a posthumous letter from his mother what their occasional dinner “dates” had meant to her. Another legend we’re familiar with features a meme used in the one-eyed mother story (the coming to light of the enduring love of the person who died for the completely unworthy person she’d lavished it on), but that one involves a terminally ill woman and her cheating husband. In it, an about-to-be-spurned wife begs the adulterous hoon she’d married to stick around for another 30 days and to carry her over the threshold of their home once every day of that month as her way of keeping him around long enough for her to kick the bucket and thus spare their son the knowledge that his parents were on the verge of divorce.\", 'label': 'false', 'scored_sentences': \"In April 2005, we spotted a tearjerker on the Internet about a mother who gave up one of her eyes to a son who had lost one of his at an early age. One day, a letter regarding a school reunion came to my house. I hated her... She was such an embarrassment. She cooked for students and teachers to support the family. A further twist was provided in the original: rather than gaining the news of his mother's death from neighbors (who hand him her letter), the son instead discovered the woman who bore him lying dead on the floor of what used to be his childhood home, her missive to him clutched in her lifeless hand: Give your parents roses while they are alive, not deadMY mom only had one eye.\", 'justification_sentences': ['The one-eyed mother story expounds upon two moral messages: the unconditional, all-encompassing love we expect mothers to always feel for their children, and the admonition to not put off cherishing loved ones and appreciating their sacrifices while they’re still around.']}\n"
     ]
    }
   ],
   "source": [
    "sa_args = get_model_args()\n",
    "\n",
    "# sa_args.dataset_name = 'liar'\n",
    "# sa_args.sentences_path = \"/Users/jolly/PycharmProjects/COPENLU/data-used-for-HE-prep/liar/results_serialized_test_filtered.jsonl\"\n",
    "# sa_args.dataset_path = \"/Users/jolly/PycharmProjects/COPENLU/data-used-for-HE-prep/liar/ruling_oracles_test.tsv\"\n",
    "# dataset = get_dataset(sa_args)\n",
    "# pipeline_inp = [line for line in open('/Users/jolly/PycharmProjects/COPENLU/data-used-for-HE-prep/liar/liar_sup_test.txt', 'r')] #sa_inp (pipeline-inp)+ '\\t' +sa_out\n",
    "# pipeline_out = [line for line in open('/Users/jolly/PycharmProjects/COPENLU/data-used-for-HE-prep/liar/liar_sup_test_pegasus.txt', 'r')]\n",
    "\n",
    "sa_args.dataset_name = 'pubhealth'\n",
    "sa_args.sentences_path = \"/Users/jolly/PycharmProjects/COPENLU/data-used-for-HE-prep/pubhealth/results_serialized_test_filtered.jsonl\"\n",
    "sa_args.dataset_path = \"/Users/jolly/PycharmProjects/COPENLU/data-used-for-HE-prep/pubhealth/test.tsv\"\n",
    "dataset = get_dataset(sa_args)\n",
    "pipeline_inp = [line for line in open('/Users/jolly/PycharmProjects/COPENLU/data-used-for-HE-prep/pubhealth/pub_sup_test.txt', 'r')] #sa_inp (pipeline-inp)+ '\\t' +sa_out\n",
    "pipeline_out = [line for line in open('/Users/jolly/PycharmProjects/COPENLU/data-used-for-HE-prep/pubhealth/pub_sup_test_pegasus.txt', 'r')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep for Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "random.seed(420)# - To save data for task 1\n",
    "final_data = []\n",
    "\n",
    "for org, inp, out in zip(dataset, pipeline_inp, pipeline_out):\n",
    "    \n",
    "    claim = org[\"statement\"]\n",
    "    veracity_label = org[\"label\"]\n",
    "    pipe_inp = inp.split(\"\\t\")[0]\n",
    "    pipe_out = out\n",
    "    \n",
    "    line_data = {\n",
    "        \"claim\": claim,\n",
    "        \"label\": veracity_label,\n",
    "        \"pipe_inp\": pipe_inp,\n",
    "        \"pipe_out\": pipe_out}\n",
    "    \n",
    "    final_data.append(line_data)\n",
    "\n",
    "final_data_40 = []\n",
    "for idx, line in enumerate(random.sample(final_data, 40)):\n",
    "    line[\"id\"] = idx+1\n",
    "    final_data_40.append(line)\n",
    "    \n",
    "json.dump(final_data_40, open(\"he_pub_task1.json\", \"w\"), indent=2)\n",
    "print(len(final_data_40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep for Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_final_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "#To save data for task2\n",
    "\n",
    "random.seed(40) \n",
    "\n",
    "final_data = []\n",
    "\n",
    "for org, inp, out in zip(dataset, pipeline_inp, pipeline_out):\n",
    "    \n",
    "    claim = org[\"statement\"]\n",
    "    veracity_label = org[\"label\"]\n",
    "    pipe_inp = inp.split(\"\\t\")[0]\n",
    "    pipe_out = out\n",
    "    \n",
    "    line_data = {\n",
    "        \"claim\": claim,\n",
    "        \"label\": veracity_label,\n",
    "        \"just\": pipe_inp,\n",
    "        \"just_type\": \"pipe_inp\"\n",
    "    }\n",
    "    \n",
    "    final_data.append(line_data)\n",
    "for idx, line in enumerate(random.sample(final_data, 30)):\n",
    "    new_final_data.append(line)\n",
    "print(len(new_final_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "final_data_60 = []\n",
    "for idx, line in enumerate(random.sample(new_final_data, 60)):\n",
    "    line[\"id\"] = idx+1\n",
    "    final_data_60.append(line)\n",
    "    \n",
    "json.dump(final_data_60, open(\"he_pub_task2.json\", \"w\"), indent=2)\n",
    "print(len(final_data_60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read SA output file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CleanSents using Paraphrase Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import language_tool_python\n",
    "\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "model_name = 'tuner007/pegasus_paraphrase'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "model_sbert = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "num_beams = 10\n",
    "num_return_sequences = 10\n",
    "\n",
    "def get_response(input_text,num_return_sequences,num_beams):\n",
    "    batch = tokenizer([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "    translated = model.generate(**batch, max_length=60,num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text\n",
    "\n",
    "def gramatical_tool(sent):\n",
    "    matches = tool.check(sent)\n",
    "    return language_tool_python.utils.correct(sent, matches)\n",
    "\n",
    "def sentence_level_semantic_scorer_sbert(org, rep):\n",
    "    org_embeds = model_sbert.encode(org)\n",
    "    rep_embeds = model_sbert.encode(rep)\n",
    "    return torch.FloatTensor([util.pytorch_cos_sim(e1, e2) for e1, e2 in zip(org_embeds, rep_embeds)])\n",
    "\n",
    "def post_process(text):\n",
    "    valid_sents = []\n",
    "    for i in sent_tokenize(text):\n",
    "        i = gramatical_tool(i)\n",
    "        doc = nlp(i)\n",
    "        verbs = [token.text for token in doc if token.pos_ in ['VERB', 'AUX']]\n",
    "        if len(verbs)>0:\n",
    "            valid_sents.append(i)\n",
    "            \n",
    "    return \" \".join(valid_sents)\n",
    "\n",
    "def pegasus(text):\n",
    "    temp = []\n",
    "    for i in sent_tokenize(text):\n",
    "        if len(i.split(\" \")) == 1:\n",
    "            temp.append(i)\n",
    "            continue\n",
    "        else:\n",
    "            all_responses = get_response(i, num_return_sequences, num_beams)\n",
    "            temp_str = ''\n",
    "            sim = sentence_level_semantic_scorer_sbert(all_responses, [i]*10)\n",
    "            max_sim_rep = all_responses[torch.argmax(sim)]    \n",
    "            temp.append(max_sim_rep)\n",
    "    \n",
    "    return(\" \".join(temp))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = json.load(open(\"he_data_liar.json\"))\n",
    "for line in tqdm(outs):\n",
    "    line['sa_pp'] = post_process(line[\"sa_out\"])\n",
    "    line['sa_pegasus'] = pegasus(line[\"sa_pp\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json.dump(outs, open('new_postprocess_liar.json', 'w+'))\n",
    "import json\n",
    "outs = json.load(open(\"new_postprocess_liar.json\"))\n",
    "for line in outs:\n",
    "    print(\"sa_inp\", line[\"sa_inp\"])\n",
    "    print(\"-----------\")\n",
    "    print(\"sa_out\", line[\"sa_out\"])\n",
    "    print(\"-----------\")\n",
    "    print(\"sa_pp\", line[\"sa_pp\"])\n",
    "    print(\"-----------\")\n",
    "    print(\"sa_pegasus\", line[\"sa_pegasus\"])\n",
    "    print(\"-----------\")\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JustFact: Generating fact-checking explainations in unsupervised settings\n",
    "\n",
    "Pipeline - Sentences from RC's --> SA --> post-processing to remove grammatical errors --> Pegasus to make it more consise\n",
    "\n",
    "Human Eval - Using two justifications - pipeline inp (SA inp) & pipeline out (pegasus out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(\"cpu\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scorer_batch(sentences):\n",
    "    #Gpt for fluency\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tensor_input = {k: v.to(\"cpu\") for k,v in tokenizer(sentences, padding=True, truncation=True, return_tensors='pt').items()}\n",
    "\n",
    "\n",
    "    lm_labels = tensor_input[\"input_ids\"].detach().clone()\n",
    "    lm_labels[lm_labels[:, :] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "    outputs = model(input_ids=tensor_input[\"input_ids\"],\n",
    "                attention_mask= tensor_input[\"attention_mask\"],\n",
    "                return_dict=True)\n",
    "\n",
    "    lm_logits = outputs.logits\n",
    "    shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "    shift_labels = lm_labels[..., 1:].contiguous()\n",
    "    \n",
    "    print([tokenizer._convert_id_to_token(i) for i in shift_labels.tolist()[0]])\n",
    "\n",
    "    loss_fct = CrossEntropyLoss(ignore_index=-100, reduction='none')  # give CE loss at each word generation step\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    \n",
    "    log_prob_sum = loss.reshape(-1, shift_labels.shape[-1]) #.sum(dim=1)\n",
    "    log_prob_sum1 = torch.exp(-loss.reshape(-1, shift_labels.shape[-1])) #.sum(dim=1)\n",
    "    len_sum = tensor_input[\"attention_mask\"][..., 1:].contiguous() #.sum(dim=1)\n",
    "    \n",
    "    #prob_products_per_sample = torch.exp(-1 * (log_prob_sum/len_sum)).cpu()\n",
    "\n",
    "    print(log_prob_sum)\n",
    "    #print(log_prob_sum1)\n",
    "    print(len_sum)\n",
    "    \n",
    "    print(log_prob_sum.sum(dim=1))\n",
    "    #print(log_prob_sum1)\n",
    "    print(len_sum.sum(dim=1))\n",
    "    print(log_prob_sum.sum(dim=1) / len_sum.sum(dim=1))\n",
    "    \n",
    "    print(\"\\nFinal:\", 100 * torch.exp(- 1 * (log_prob_sum.sum(dim=1) / len_sum.sum(dim=1))))\n",
    "    \n",
    "    #return (prob_products_per_sample * 100)\n",
    "    \n",
    "sents = ['I bought bananas, apples, and orange juice from the supermarket.']\n",
    "scorer_batch(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep SA input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(sent):\n",
    "    sent = sent.replace(\"’\", \"'\")\n",
    "    sent = sent.replace(\"‘\", \"`\")\n",
    "    sent = sent.replace('\"', \"''\")\n",
    "    sent = sent.replace(\"—\", \"--\")\n",
    "    sent = sent.replace(\"…\", \"...\")\n",
    "    sent = sent.replace(\"–\", \"--\")\n",
    "\n",
    "    return sent\n",
    "\n",
    "def get_dataset(scored_sentences_path, dataset_path, dataset_name, top_n, parser):\n",
    "\n",
    "    if dataset_name == 'liar_plus':\n",
    "        df = pd.read_csv(dataset_path, sep='\\t', index_col=0)\n",
    "        df = df.dropna()\n",
    "        columns = ['dummy', 'id', 'statement', 'justification',\n",
    "               'ruling_without_summary', 'label', 'just_tokenized',\n",
    "               'ruling_tokenized', 'statement_tokenized', 'oracle_ids']\n",
    "        print(df.columns)\n",
    "        print(columns)\n",
    "        df.columns = columns\n",
    "        \n",
    "    elif dataset_name == 'pub_health':\n",
    "        df = pd.read_csv(dataset_path, sep='\\t', index_col=0)\n",
    "        df = df.dropna()\n",
    "        \n",
    "        columns = ['claim_id', 'claim', 'date_published', 'explanation',\n",
    "                   'fact_checkers', 'main_text', 'sources', 'label', 'subjects']\n",
    "        \n",
    "        if len(df.columns) == 10:\n",
    "            columns = ['dummy'] + columns\n",
    "        \n",
    "        df.columns = columns\n",
    "        \n",
    "    scored_sentences = [json.loads(line) for line in open(scored_sentences_path)]\n",
    "    scored_sentences = {item[\"id\"]: sorted(item['sentence_scores'], key=lambda x: x[1], reverse=True)[:top_n] for item in scored_sentences}\n",
    "    \n",
    "    \n",
    "    inp_scored_sentences = {}\n",
    "    for k, v in scored_sentences.items():\n",
    "        \n",
    "        temp = []\n",
    "        for sent in v:\n",
    "            temp.append(sent[0])\n",
    "        inp_scored_sentences[k] = clean_str(\" \".join(temp))\n",
    "\n",
    "    scored_sentences = inp_scored_sentences\n",
    "    \n",
    "    \n",
    "    if dataset_name == 'liar_plus':\n",
    "        \n",
    "        df['scored_sentences'] = df.apply(lambda x: scored_sentences.get(x['id'], None), axis=1)\n",
    "        df = df[df['scored_sentences'] != None]\n",
    "        df['justification_sentences'] = df.apply(lambda x: sent_tokenize(x['justification']), axis=1)\n",
    "        df = df[['id', 'statement', 'justification', 'label', 'scored_sentences',\n",
    "             'justification_sentences']]\n",
    "        \n",
    "    elif dataset_name == 'pub_health':\n",
    "        df['claim_id'] = df['claim_id'].astype('str')\n",
    "        df['scored_sentences'] = df.apply(lambda x: scored_sentences.get(x['claim_id'], None), axis=1)\n",
    "        df = df[df['scored_sentences'] != None]\n",
    "        df['justification_sentences'] = df.apply(lambda x: sent_tokenize(x['explanation']), axis=1)\n",
    "        df = df[['claim_id', 'claim', 'explanation', 'label', 'scored_sentences',\n",
    "             'justification_sentences']]\n",
    "        \n",
    "        \n",
    "    dataset = [row.to_dict() for i, row in df.iterrows()]\n",
    "    new_dataset = []\n",
    "    if dataset_name == 'liar_plus':\n",
    "        for i in dataset:\n",
    "            if i[\"scored_sentences\"] is None or i[\"id\"] == '2001.json': #Sentence in Liarplus is too long:\n",
    "                continue\n",
    "            else:\n",
    "                new_dataset.append(i)\n",
    "    elif dataset_name == 'pub_health':\n",
    "        for i in dataset:\n",
    "        \n",
    "            if i[\"scored_sentences\"] is None or i[\"scored_sentences\"] == None:\n",
    "                continue\n",
    "            else:\n",
    "                new_dataset.append(i)\n",
    "    \n",
    "\n",
    "    print(f'Size of dataset: {len(dataset)}')\n",
    "    print(f'Size of new dataset: {len(new_dataset)}')\n",
    "    print('Sample: ', dataset[0])\n",
    "    if len(new_dataset)!=0:\n",
    "        print('Sample: ', new_dataset[0])\n",
    "\n",
    "    return \n",
    "\n",
    "scored_sentences_path = \"../../DATA-COPE-Project-DIKUServer/unsup_scores_liar/sentence_scores_val.jsonl\" #Each line is a json\n",
    "scored_sentences_path1 = \"../../DATA-COPE-Project-DIKUServer/unsup_scores_pubhealth/sentence_scores_test.jsonl\"\n",
    "\n",
    "dataset_path = \"../../liar_data/ruling_oracles_val.tsv\"\n",
    "dataset_path1 = \"../../DATA-COPE-Project-DIKUServer/PUBHEALTH/test.tsv\"\n",
    "\n",
    "get_dataset(scored_sentences_path1, dataset_path1, 'pub_health', 6, parser)\n",
    "#get_dataset(scored_sentences_path, dataset_path, 'liar_plus', 6, parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
