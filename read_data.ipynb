{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "\n",
    "from data_loader import get_dataset_df\n",
    "from run_sa import get_dataset\n",
    "from rouge_score import rouge_scorer\n",
    "from SA.args import get_model_args\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from nltk.parse.corenlp import CoreNLPParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CoreNLPParser('http://localhost:9000', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_args = get_model_args()\n",
    "\n",
    "sa_args.dataset_name = 'liar'\n",
    "sa_args.sentences_path = \"/Users/jolly/PycharmProjects/COPENLU/Data_HE/liar/results_serialized_test_filtered.jsonl\"\n",
    "sa_args.dataset_path = \"/Users/jolly/PycharmProjects/COPENLU/Data_HE/liar/ruling_oracles_test.tsv\"\n",
    "dataset = get_dataset(sa_args)\n",
    "SA = [line for line in open('/Users/jolly/PycharmProjects/COPENLU/Data_HE/liar/liar_sup_test.txt', 'r')] #sa_inp + '\\t' +sa_out\n",
    "SA_PM = [line for line in open('/Users/jolly/PycharmProjects/COPENLU/Data_HE/liar/liar_sup_test_filter.txt', 'r')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep for Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(420)# - To save data for task 1\n",
    "final_data = []\n",
    "\n",
    "for org, sa, sa_pm in zip(dataset, SA, SA_PM):\n",
    "    \n",
    "    claim = org[\"statement\"]\n",
    "    veracity_label = org[\"label\"]\n",
    "    sa_inp = sa.split(\"\\t\")[0]\n",
    "    sa_out = sa.split(\"\\t\")[1]\n",
    "    \n",
    "    line_data = {\n",
    "        \"claim\": claim,\n",
    "        \"label\": veracity_label,\n",
    "        \"sa_inp\": sa_inp,\n",
    "        \"sa_out\": sa_out,\n",
    "        \"sa_pm\": sa_pm\n",
    "    }\n",
    "    \n",
    "    final_data.append(line_data)\n",
    "\n",
    "final_data_40 = []\n",
    "for idx, line in enumerate(random.sample(final_data, 40)):\n",
    "    line[\"id\"] = idx+1\n",
    "    final_data_40.append(line)\n",
    "    \n",
    "json.dump(final_data_40, open(\"he_data_liar.json\", \"w\"), indent=2)\n",
    "print(len(final_data_40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep for Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_final_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save data for task2\n",
    "\n",
    "#random.seed(20) #- To save data for task 2 -sa_inps\n",
    "#random.seed(30) #- To save data for task 2 -sa_outs\n",
    "random.seed(40) #- To save data for task 2 -sa_pm justs\n",
    "\n",
    "final_data = []\n",
    "\n",
    "for org, sa, sa_pm in zip(dataset, SA, SA_PM):\n",
    "    \n",
    "    claim = org[\"statement\"]\n",
    "    veracity_label = org[\"label\"]\n",
    "    sa_inp = sa.split(\"\\t\")[0]\n",
    "    sa_out = sa.split(\"\\t\")[1]\n",
    "    \n",
    "    line_data = {\n",
    "        \"claim\": claim,\n",
    "        \"label\": veracity_label,\n",
    "        \"just\": sa_pm,\n",
    "        \"just_type\": \"sa_pm\"\n",
    "    }\n",
    "    \n",
    "    final_data.append(line_data)\n",
    "for idx, line in enumerate(random.sample(final_data, 20)):\n",
    "    new_final_data.append(line)\n",
    "print(len(new_final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_60 = []\n",
    "for idx, line in enumerate(random.sample(new_final_data, 60)):\n",
    "    line[\"id\"] = idx+1\n",
    "    final_data_60.append(line)\n",
    "    \n",
    "json.dump(final_data_60, open(\"he_data_liar_task2.json\", \"w\"), indent=2)\n",
    "print(len(final_data_60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read SA output file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CleanSents using Paraphrase Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import language_tool_python\n",
    "\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "model_name = 'tuner007/pegasus_paraphrase'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "model_sbert = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "num_beams = 10\n",
    "num_return_sequences = 10\n",
    "\n",
    "def get_response(input_text,num_return_sequences,num_beams):\n",
    "    batch = tokenizer([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "    translated = model.generate(**batch, max_length=60,num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text\n",
    "\n",
    "def gramatical_tool(sent):\n",
    "    matches = tool.check(sent)\n",
    "    return language_tool_python.utils.correct(sent, matches)\n",
    "\n",
    "def sentence_level_semantic_scorer_sbert(org, rep):\n",
    "    org_embeds = model_sbert.encode(org)\n",
    "    rep_embeds = model_sbert.encode(rep)\n",
    "    return torch.FloatTensor([util.pytorch_cos_sim(e1, e2) for e1, e2 in zip(org_embeds, rep_embeds)])\n",
    "\n",
    "def post_process(text):\n",
    "    valid_sents = []\n",
    "    for i in sent_tokenize(text):\n",
    "        i = gramatical_tool(i)\n",
    "        doc = nlp(i)\n",
    "        verbs = [token.text for token in doc if token.pos_ in ['VERB', 'AUX']]\n",
    "        if len(verbs)>0:\n",
    "            valid_sents.append(i)\n",
    "            \n",
    "    return \" \".join(valid_sents)\n",
    "\n",
    "def pegasus(text):\n",
    "    temp = []\n",
    "    for i in sent_tokenize(text):\n",
    "        if len(i.split(\" \")) == 1:\n",
    "            temp.append(i)\n",
    "            continue\n",
    "        else:\n",
    "            all_responses = get_response(i, num_return_sequences, num_beams)\n",
    "            temp_str = ''\n",
    "            sim = sentence_level_semantic_scorer_sbert(all_responses, [i]*10)\n",
    "            max_sim_rep = all_responses[torch.argmax(sim)]    \n",
    "            temp.append(max_sim_rep)\n",
    "    \n",
    "    return(\" \".join(temp))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = json.load(open(\"he_data_liar.json\"))\n",
    "for line in tqdm(outs):\n",
    "    line['sa_pp'] = post_process(line[\"sa_out\"])\n",
    "    line['sa_pegasus'] = pegasus(line[\"sa_pp\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json.dump(outs, open('new_postprocess_liar.json', 'w+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa_inp But 90 percent of them, 90 percent, do not then show up in court later.'' That's substantially lower than the 90 percent figure Flake cited. ''And then what the record shows is that they're told to appear later in court, where their case will be adjudicated. In this context, Sen. Jeff Flake, R-Ariz., offered a notable statistic about the judicial treatment of people who arrive at the U.S. border. Between 2003 and 2012, the percentage of all immigrants who failed to appear in court after being released has bounced between 20 percent and 40 percent, settling in at about 30 percent at the end of that time span. This is a related and notable issue, but somewhat different from what Flake or Goodlatte said.\n",
      "-----------\n",
      "sa_out But 90 percent of them, 90 percent, do not show up in court.'' That's substantially lower than the 90 percent figure Flake cited. ''And what the record shows about the judicial treatment of people who arrive at the U.S. border is that they're told to appear in court, where their case will be adjudicated. , Sen. Jeff Flake, R-Ariz., . Between 2003 and 2012, the percentage of all immigrants who failed to appear in court has bounced between 20 percent and 40 percent, settling in at about 30 percent at the end of that time after being released later . , but .\n",
      "\n",
      "-----------\n",
      "sa_pp But 90 percent of them, 90 percent, do not show up in court.'' That's substantially lower than the 90 percent figure Flake cited. ''And what the record shows about the judicial treatment of people who arrive at the U.S. border is that they're told to appear in court, where their case will be adjudicated. Between 2003 and 2012, the percentage of all immigrants who failed to appear in court has bounced between 20 percent and 40 percent, settling in at about 30 percent at the end of that time after being released later.\n",
      "-----------\n",
      "sa_pegasus 90 percent of them do not show up in court. That's not as high as the 90 percent figure cited by Flake. The record shows that people who arrive at the U.S. border are told to appear in court. Between 2003 and 2012 the percentage of immigrants who failed to appear in court has bounced between 20 percent and 40 percent, and settled in at 30 percent at the end of that time.\n",
      "-----------\n",
      "\n",
      "sa_inp About a dozen of them hit middle-income taxpayers, breaking that promise. Ryan continued, ''Yeah, tax rates -- he already passed all these Obamacare taxes. The Ways and Means list marks the tax increases that affect ''middle-income taxpayers'' with an asterisk. As you'll see, many of these are new taxes, some of them primarily hit the middle-class, others hit certain people within the middle class (along with other people not in the middle class), and others are debatable. Not your income tax, not your payroll tax, not your capital gains taxes, not any of your taxes.'' (11) A 40 percent excise tax on employer-provided ''Cadillac'' health insurance plans costing more than $10,200 for individuals and $27,500 for families.\n",
      "-----------\n",
      "sa_out About a dozen of them all these Obamacare taxes hit middle-income taxpayers, . Ryan continued, ''Yeah, tax rates -- he passed. The Ways and Means marks the tax increases that affect ''middle-income taxpayers'' with an asterisk. As you'll see, many of these are new taxes, some of them hit the middle-class, others hit certain people within the middle class (along with other people not in the middle class), and others are debatable. Not your income tax, not your payroll tax, not your capital gains taxes, not any of your taxes.'' (11) A 40 percent excise tax on employer-provided ''Cadillac'' health insurance plans costing more than $10,200 for individuals and $27,500 for families.\n",
      "\n",
      "-----------\n",
      "sa_pp About a dozen of them all these Obamacare taxes hit middle-income taxpayers, Ryan continued, ''Yeah, tax rates -- he passed. The Ways and Means marks the tax increases that affect ''middle-income taxpayers'' with an asterisk. As you'll see, many of these are new taxes, some of them hit the middle-class, others hit certain people within the middle class (along with other people not in the middle class), and others are debatable. (11) A 40 percent excise tax on employer-provided ''Cadillac'' health insurance plans costing more than $10,200 for individuals and $27,500 for families.\n",
      "-----------\n",
      "sa_pegasus Ryan said that about a dozen of the taxes hit middle income taxpayers. The tax increases that affect middle-income taxpayers are marked with an asterisk in the Ways and Means. Many of these are new taxes, some of them hit the middle-class, others hit certain people within the middle class, and others are debatable. A 40 percent excise tax on employer-supplied ''Cadillac'' health insurance plans costing more than $10,200 for individuals and $27,500 for families.\n",
      "-----------\n",
      "\n",
      "sa_inp Michael Reagan and I were talking just the other day, Charlie, that I came to the Republican Party sooner in age than his dad, Ronald Reagan, did,'' Perry told debate moderator Charlie Rose on Oct. 11, 2011. Rick Perry wasn't always a Republican. PolitiFact Texas checked it out. He remained a Democrat even as he supported Republican presidential candidates, according to Melissa Giller, director of communications and programs at Reagan's presidential library. His opponents like to remind him of that, as Minnesota Rep. Michele Bachmann did in a Republican presidential primary debate at Dartmouth College in Hanover, N.H. And Perry likes to respond that another notable Republican once had a ''D'' behind his name too. His words then, also repeated from a conversation with the former president's son: ''I became a Republican sooner in my life than your dad did.''\n",
      "-----------\n",
      "sa_out were talking, Charlie, that I came to the Republican Party in age sooner than his dad, Ronald Reagan, did,'' Perry told debate moderator Charlie Rose on Oct. 11, 2011. Rick Perry wasn't a Republican. PolitiFact Texas checked it out. He remained a Democrat then even as he supported Republican presidential candidates, according to Melissa Giller, director of communications and programs at Reagan's presidential library. His opponents like to remind him of that, as Minnesota Rep. Michele Bachmann did in a Republican presidential primary debate just the other day at Dartmouth College in Hanover , N.H. And Perry likes to respond that another notable Republican had a ''D'' . His words, also repeated from a conversation once with the former president's son: ''I became a Republican sooner in my life than your dad did.''\n",
      "\n",
      "-----------\n",
      "sa_pp Were talking, Charlie, that I came to the Republican Party in age sooner than his dad, Ronald Reagan, did,'' Perry told debate moderator Charlie Rose on Oct. 11, 2011. Rick Perry wasn't a Republican. Political Texas checked it out. He remained a Democrat then even as he supported Republican presidential candidates, according to Melissa Miller, director of communications and programs at Reagan's presidential library. His opponents like to remind him of that, as Minnesota Rep. Michele Eichmann did in a Republican presidential primary debate just the other day at Dartmouth College in Hanover, N.H. And Perry likes to respond that another notable Republican had a ''D''. His words, also repeated from a conversation once with the former president's son: ''I became a Republican sooner in my life than your dad did.''\n",
      "-----------\n",
      "sa_pegasus During the debate with Charlie Rose on October 11,2011, the debate host asked if he came to the Republican Party sooner than his father, Ronald Reagan. Rick Perry wasn't a Republican. Political Texas checked it out. According to the director of communications and programs at Reagan's presidential library, he remained a Democrat even as he supported Republican presidential candidates. His opponents remind him of that and he likes to respond that another Republican had a ''D''. I became a Republican sooner in my life than your dad did, he said in a conversation with the former president's son.\n",
      "-----------\n",
      "\n",
      "sa_inp ''Road congestion costs rush-hour drivers in Austin and Dallas more than $1,000 a year,'' Abbott said. ''And in Houston, it's even more -- almost $1,500 a year.'' And, according to the institute, the peak congestion cost for Texans in 2014 came out to $17.67 per hour for personal travel. While fuel costs have declined steadily since August 2014, that won't be reflected until next year's scorecard. He made the case by citing what daily traffic congestion costs Texas motorists in dollars, over the course of a year. ''I'm not sure anybody, as a matter of public policy, would argue that makes sense.''\n",
      "-----------\n",
      "sa_out ''Road congestion costs rush-hour drivers in Austin and Dallas daily more than $1,000 a year,'' Abbott said. ''And in Houston, it's even more in dollars per hour -- almost $1,500 a year.'' And, according to the institute, the peak congestion cost for Texans came out to $17.67 in 2014 for personal travel. While fuel costs have declined since August 2014, that won't be reflected until next year's scorecard. He made the case that makes sense by citing what traffic congestion costs Texas motorists, over the course of a year. ''I'm not sure anybody, as a matter of public policy, would argue.''\n",
      "\n",
      "-----------\n",
      "sa_pp ''Road congestion costs rush-hour drivers in Austin and Dallas daily more than $1,000 a year,'' Abbott said. ''And in Houston, it's even more in dollars per hour -- almost $1,500 a year.'' And, according to the institute, the peak congestion cost for Texans came out to $17.67 in 2014 for personal travel. While fuel costs have declined since August 2014, that won't be reflected until next year's scorecard. He made the case that makes sense by citing what traffic congestion costs Texas motorists, over the course of a year. ''I'm not sure anybody, as a matter of public policy, would argue.''\n",
      "-----------\n",
      "sa_pegasus Rush-hour drivers in Austin and Dallas spend more than $1,000 a year on road congestion. In Houston, it's even more in dollars per hour. According to the institute, the peak congestion cost for Texans was $17.67 for personal travel in 2014. Since August of last year, fuel costs have declined, but that won't be reflected in the scorecard next year. He made the case that traffic congestion costs Texas motorists over the course of a year. I'm not sure if anyone would argue about public policy.\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sa_inp The release claims that Koster ''fell silent'' on investigating the website Backpage.com in 2011, after receiving ''over $12,000 in campaign contributions'' from a legal and lobbying firm representing the site, SNR Denton. Backpage, a free classifieds website, has been criticized for promoting prostitution and helping facilitate human trafficking. According to the campaign release, Koster ceased any efforts against Backpage following donations from SNR Denton. Backpage has yet to comply. Koster's office referenced this letter. The letter asked attorneys general to sign on to a letter urging Congress to amend the Communications Decency Act of 1996.\n",
      "-----------\n",
      "sa_out The letter The release in 2011 claims that Koster ''fell silent'' on investigating the website Backpage.com, after receiving ''over $12,000 in campaign contributions'' from a legal and lobbying firm, SNR Denton. Backpage, , has been criticized for promoting prostitution and helping facilitate human trafficking. According to the campaign release, Koster ceased any efforts against Backpage representing the site following donations from SNR Denton. Backpage has yet to comply . Koster's office . asked attorneys general to sign on to a letter urging Congress to amend the Communications Decency Act of 1996 .\n",
      "\n",
      "-----------\n",
      "sa_pp The letter The release in 2011 claims that Foster ''fell silent'' on investigating the website Backpage.com, after receiving ''over $12,000 in campaign contributions'' from a legal and lobbying firm, SNR Denton. Back page,, has been criticized for promoting prostitution and helping facilitate human trafficking. According to the campaign release, Foster ceased any efforts against Back page representing the site following donations from SNR Denton. Back page has yet to comply. Asked attorneys general to sign on to a letter urging Congress to amend the Communications Decency Act of 1996.\n",
      "-----------\n",
      "sa_pegasus The letter claims that Foster ''fell silent'' on investigating the website Backpage.com, after receiving over $12,000 in campaign contributions from a legal and lobbying firm. Back page has been criticized for promoting prostitution. According to the campaign release, Foster ceased efforts against the Back page after donations from SNR Denton. The back page has not complied yet. Attorneys general were asked to sign on to a letter urging Congress to amend the Communications Decency Act of 1996.\n",
      "-----------\n",
      "\n",
      "sa_inp ''Adjusted for inflation, the average Georgia family in effect makes $6,000 less than the average family did 10 years ago,'' Carter said. He actually was conservative in saying what's happened to Georgia's median family income. Alabama and South Carolina trailed the state, ranking 42nd and 48th respectively. They point out that Georgia's unemployment rate -- while 40th for the nation at 7.7 percent in November 2013 -- is still the lowest it has been in five years. Deal officials cite other numbers showing that the economy is improving. The U.S. Census Bureau report said it was actually $6,682 less in 2012 than in 2002, when inflation is factored in.\n",
      "-----------\n",
      "sa_out ''Adjusted for inflation, the average Georgia family makes $6,000 less than the average family did 10 years ago,'' Carter said. He was conservative in saying what's happened to Georgia's median family income. Alabama in 2012 and South Carolina in 2002 trailed, ranking 42nd and 48th respectively. They point out that Georgia's unemployment rate -- while 40th for the nation in November 2013 at 7.7 percent -- is the lowest it has been in five years. Deal officials cite showing that the economy is improving. The U.S. Census Bureau report in still other numbers the state said it was $6,682 less than, when inflation is factored in.\n",
      "\n",
      "-----------\n",
      "sa_pp ''Adjusted for inflation, the average Georgia family makes $6,000 less than the average family did 10 years ago,'' Carter said. He was conservative in saying what's happened to Georgia's median family income. Alabama in 2012 and South Carolina in 2002 trailed, ranking 42nd and 48th respectively. They point out that Georgia's unemployment rate -- while 40th for the nation in November 2013 at 7.7 percent -- is the lowest it has been in five years. Deal officials cite showing that the economy is improving. The U.S. Census Bureau report in still other numbers the state said it was $6,682 less than, when inflation is factored in.\n",
      "-----------\n",
      "sa_pegasus The average Georgia family makes $6,000 less than they did a decade ago. He said what's happened to Georgia's median family income was conservative. South Carolina was 48th in 2002 and Alabama was 42nd in 2012. They point out that Georgia's unemployment rate is the lowest it has been in five years. Deal officials say that the economy is improving. The state's report from the U.S. Census Bureau said it was $6,682 less than when inflation is factored in.\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "outs = json.load(open(\"new_postprocess_liar.json\"))\n",
    "for line in outs:\n",
    "    print(\"sa_inp\", line[\"sa_inp\"])\n",
    "    print(\"-----------\")\n",
    "    print(\"sa_out\", line[\"sa_out\"])\n",
    "    print(\"-----------\")\n",
    "    print(\"sa_pp\", line[\"sa_pp\"])\n",
    "    print(\"-----------\")\n",
    "    print(\"sa_pegasus\", line[\"sa_pegasus\"])\n",
    "    print(\"-----------\")\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JustFact: Generating fact-checking explainations in unsupervised settings\n",
    "\n",
    "Pipeline - Sentences from RC's --> SA --> post-processing to remove grammatical errors --> Pegasus to make it more consise\n",
    "\n",
    "Human Eval - Using two justifications - pipeline inp (SA inp) & pipeline out (pegasus out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(\"cpu\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scorer_batch(sentences):\n",
    "    #Gpt for fluency\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tensor_input = {k: v.to(\"cpu\") for k,v in tokenizer(sentences, padding=True, truncation=True, return_tensors='pt').items()}\n",
    "\n",
    "\n",
    "    lm_labels = tensor_input[\"input_ids\"].detach().clone()\n",
    "    lm_labels[lm_labels[:, :] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "    outputs = model(input_ids=tensor_input[\"input_ids\"],\n",
    "                attention_mask= tensor_input[\"attention_mask\"],\n",
    "                return_dict=True)\n",
    "\n",
    "    lm_logits = outputs.logits\n",
    "    shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "    shift_labels = lm_labels[..., 1:].contiguous()\n",
    "    \n",
    "    print([tokenizer._convert_id_to_token(i) for i in shift_labels.tolist()[0]])\n",
    "\n",
    "    loss_fct = CrossEntropyLoss(ignore_index=-100, reduction='none')  # give CE loss at each word generation step\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    \n",
    "    log_prob_sum = loss.reshape(-1, shift_labels.shape[-1]) #.sum(dim=1)\n",
    "    log_prob_sum1 = torch.exp(-loss.reshape(-1, shift_labels.shape[-1])) #.sum(dim=1)\n",
    "    len_sum = tensor_input[\"attention_mask\"][..., 1:].contiguous() #.sum(dim=1)\n",
    "    \n",
    "    #prob_products_per_sample = torch.exp(-1 * (log_prob_sum/len_sum)).cpu()\n",
    "\n",
    "    print(log_prob_sum)\n",
    "    #print(log_prob_sum1)\n",
    "    print(len_sum)\n",
    "    \n",
    "    print(log_prob_sum.sum(dim=1))\n",
    "    #print(log_prob_sum1)\n",
    "    print(len_sum.sum(dim=1))\n",
    "    print(log_prob_sum.sum(dim=1) / len_sum.sum(dim=1))\n",
    "    \n",
    "    print(\"\\nFinal:\", 100 * torch.exp(- 1 * (log_prob_sum.sum(dim=1) / len_sum.sum(dim=1))))\n",
    "    \n",
    "    #return (prob_products_per_sample * 100)\n",
    "    \n",
    "sents = ['I bought bananas, apples, and orange juice from the supermarket.']\n",
    "scorer_batch(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep SA input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(sent):\n",
    "    sent = sent.replace(\"’\", \"'\")\n",
    "    sent = sent.replace(\"‘\", \"`\")\n",
    "    sent = sent.replace('\"', \"''\")\n",
    "    sent = sent.replace(\"—\", \"--\")\n",
    "    sent = sent.replace(\"…\", \"...\")\n",
    "    sent = sent.replace(\"–\", \"--\")\n",
    "\n",
    "    return sent\n",
    "\n",
    "def get_dataset(scored_sentences_path, dataset_path, dataset_name, top_n, parser):\n",
    "\n",
    "    if dataset_name == 'liar_plus':\n",
    "        df = pd.read_csv(dataset_path, sep='\\t', index_col=0)\n",
    "        df = df.dropna()\n",
    "        columns = ['dummy', 'id', 'statement', 'justification',\n",
    "               'ruling_without_summary', 'label', 'just_tokenized',\n",
    "               'ruling_tokenized', 'statement_tokenized', 'oracle_ids']\n",
    "        print(df.columns)\n",
    "        print(columns)\n",
    "        df.columns = columns\n",
    "        \n",
    "    elif dataset_name == 'pub_health':\n",
    "        df = pd.read_csv(dataset_path, sep='\\t', index_col=0)\n",
    "        df = df.dropna()\n",
    "        \n",
    "        columns = ['claim_id', 'claim', 'date_published', 'explanation',\n",
    "                   'fact_checkers', 'main_text', 'sources', 'label', 'subjects']\n",
    "        \n",
    "        if len(df.columns) == 10:\n",
    "            columns = ['dummy'] + columns\n",
    "        \n",
    "        df.columns = columns\n",
    "        \n",
    "    scored_sentences = [json.loads(line) for line in open(scored_sentences_path)]\n",
    "    scored_sentences = {item[\"id\"]: sorted(item['sentence_scores'], key=lambda x: x[1], reverse=True)[:top_n] for item in scored_sentences}\n",
    "    \n",
    "    \n",
    "    inp_scored_sentences = {}\n",
    "    for k, v in scored_sentences.items():\n",
    "        \n",
    "        temp = []\n",
    "        for sent in v:\n",
    "            temp.append(sent[0])\n",
    "        inp_scored_sentences[k] = clean_str(\" \".join(temp))\n",
    "\n",
    "    scored_sentences = inp_scored_sentences\n",
    "    \n",
    "    \n",
    "    if dataset_name == 'liar_plus':\n",
    "        \n",
    "        df['scored_sentences'] = df.apply(lambda x: scored_sentences.get(x['id'], None), axis=1)\n",
    "        df = df[df['scored_sentences'] != None]\n",
    "        df['justification_sentences'] = df.apply(lambda x: sent_tokenize(x['justification']), axis=1)\n",
    "        df = df[['id', 'statement', 'justification', 'label', 'scored_sentences',\n",
    "             'justification_sentences']]\n",
    "        \n",
    "    elif dataset_name == 'pub_health':\n",
    "        df['claim_id'] = df['claim_id'].astype('str')\n",
    "        df['scored_sentences'] = df.apply(lambda x: scored_sentences.get(x['claim_id'], None), axis=1)\n",
    "        df = df[df['scored_sentences'] != None]\n",
    "        df['justification_sentences'] = df.apply(lambda x: sent_tokenize(x['explanation']), axis=1)\n",
    "        df = df[['claim_id', 'claim', 'explanation', 'label', 'scored_sentences',\n",
    "             'justification_sentences']]\n",
    "        \n",
    "        \n",
    "    dataset = [row.to_dict() for i, row in df.iterrows()]\n",
    "    new_dataset = []\n",
    "    if dataset_name == 'liar_plus':\n",
    "        for i in dataset:\n",
    "            if i[\"scored_sentences\"] is None or i[\"id\"] == '2001.json': #Sentence in Liarplus is too long:\n",
    "                continue\n",
    "            else:\n",
    "                new_dataset.append(i)\n",
    "    elif dataset_name == 'pub_health':\n",
    "        for i in dataset:\n",
    "        \n",
    "            if i[\"scored_sentences\"] is None or i[\"scored_sentences\"] == None:\n",
    "                continue\n",
    "            else:\n",
    "                new_dataset.append(i)\n",
    "    \n",
    "\n",
    "    print(f'Size of dataset: {len(dataset)}')\n",
    "    print(f'Size of new dataset: {len(new_dataset)}')\n",
    "    print('Sample: ', dataset[0])\n",
    "    if len(new_dataset)!=0:\n",
    "        print('Sample: ', new_dataset[0])\n",
    "\n",
    "    return \n",
    "\n",
    "scored_sentences_path = \"../../DATA-COPE-Project-DIKUServer/unsup_scores_liar/sentence_scores_val.jsonl\" #Each line is a json\n",
    "scored_sentences_path1 = \"../../DATA-COPE-Project-DIKUServer/unsup_scores_pubhealth/sentence_scores_test.jsonl\"\n",
    "\n",
    "dataset_path = \"../../liar_data/ruling_oracles_val.tsv\"\n",
    "dataset_path1 = \"../../DATA-COPE-Project-DIKUServer/PUBHEALTH/test.tsv\"\n",
    "\n",
    "get_dataset(scored_sentences_path1, dataset_path1, 'pub_health', 6, parser)\n",
    "#get_dataset(scored_sentences_path, dataset_path, 'liar_plus', 6, parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
